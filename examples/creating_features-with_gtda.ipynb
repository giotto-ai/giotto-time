{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create topological features for time series analysis\n",
    "\n",
    "Topological data analysis is the study of shapes of point clouds and can be used in time series analysis.\n",
    "\n",
    "The goal of this notebook is to showcase how the topological data analysis library ``giotto-tda`` can be used together with ``giotto-time`` to create topological features for time series analysis.\n",
    "\n",
    "The **fit_transform** paradigm used in both libraries allows to create scikit-learn-like pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gtda.time_series as ts\n",
    "import gtda.diagrams as diag\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from gtda.pipeline import Pipeline\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtime.compose import FeatureCreation\n",
    "from gtime.feature_extraction import CustomFeature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "idx = pd.date_range(start='1986-01-02', end='2019-12-31')\n",
    "df['value'] = np.random.rand(len(idx))\n",
    "df.index = idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "Various parameters related to the TDA functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 10\n",
    "embedding_time_delay = 1\n",
    "takens_dimension = 3\n",
    "takens_stride = 1\n",
    "takens_time_delay = 1\n",
    "takens_parameters_type = \"fixed\"\n",
    "sliding_window_width = 10\n",
    "sliding_stride = 1\n",
    "diags_metric = \"euclidean\"\n",
    "diags_coeff = 2\n",
    "diags_max_edge_length = np.inf\n",
    "diags_homology_dimensions = (0, 1, 2)\n",
    "diags_infinity_values = None\n",
    "amplitude_metric = \"wasserstein\"\n",
    "amplitude_order = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TDA transformers\n",
    "For more information regarding ``giotto-tda`` visit: https://github.com/giotto-ai/giotto-tda. \n",
    "Documentation: https://docs-tda.giotto.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "takens_embedding = ts.SingleTakensEmbedding(\n",
    "    parameters_type=takens_parameters_type,\n",
    "    dimension=embedding_dimension,\n",
    "    stride=takens_stride,\n",
    "    time_delay=embedding_time_delay,\n",
    ")\n",
    "\n",
    "sliding_window = ts.SlidingWindow(\n",
    "    size=sliding_window_width, stride=sliding_stride\n",
    ")\n",
    "\n",
    "vietoris_rips_persistence = VietorisRipsPersistence(\n",
    "    metric=diags_metric,\n",
    "    coeff=diags_coeff,\n",
    "    max_edge_length=diags_max_edge_length,\n",
    "    homology_dimensions=diags_homology_dimensions,\n",
    "    infinity_values=diags_infinity_values,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "diagram_scaler = diag.Scaler()\n",
    "\n",
    "amplitude = diag.Amplitude(\n",
    "    metric=amplitude_metric,\n",
    "    order=amplitude_order,\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "These helper functions will support in making the data fit giotto-tda format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_n_points(\n",
    "    n_windows: int,\n",
    "    sliding_stride: int,\n",
    "    sliding_window_width: int,\n",
    "    takens_stride: int,\n",
    "    takens_dimension: int,\n",
    "    takens_time_delay: int,\n",
    ") -> int:\n",
    "    \"\"\"Helper function to reshape TDA feature for use with giotto-time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_windows : int\n",
    "        Number of windows\n",
    "    sliding_stride : int \n",
    "        Sliding stride used in pipeline\n",
    "    sliding_window_width : int \n",
    "        Width of the window used in pipeline\n",
    "    takens_stride : int\n",
    "        Stride used in the Takens embedding\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    n_used_points : int\n",
    "        Parameter for reshaping the feature values to pandas dataframes.\n",
    "    \"\"\"\n",
    "    embedder_length = sliding_stride * (n_windows - 1) + sliding_window_width\n",
    "\n",
    "    n_used_points = (\n",
    "        takens_stride * (embedder_length - 1) + takens_dimension * takens_time_delay\n",
    "    )\n",
    "    return n_used_points\n",
    "\n",
    "\n",
    "def align_indices(X: pd.DataFrame, n_points: int, tda_feature_values: np.array) -> int:\n",
    "    \"\"\"Helper function to reshape TDA feature for use with giotto-time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame, required\n",
    "        Original time series\n",
    "    n_points : int, required\n",
    "        Output of compute_n_points\n",
    "    tda_feature_values : np.array, required\n",
    "        Results of the TDA pipeline\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output_X : pandas dataframe\n",
    "        Reshaped dataframe with feature values.\n",
    "    \"\"\"\n",
    "    output_X = X.copy()\n",
    "\n",
    "    output_X.iloc[:-n_points] = np.nan\n",
    "\n",
    "    splits = np.array_split(\n",
    "        output_X.iloc[-n_points:].index.values, len(tda_feature_values)\n",
    "    )\n",
    "\n",
    "    for index, split in enumerate(splits):\n",
    "        if isinstance(tda_feature_values[index], list) or isinstance(\n",
    "            tda_feature_values[index], np.ndarray\n",
    "        ):\n",
    "            target_value = tda_feature_values[index][0]\n",
    "        else:\n",
    "            target_value = tda_feature_values[index]\n",
    "        output_X.loc[split] = target_value\n",
    "\n",
    "    return output_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature definition\n",
    "We present four different features:\n",
    "- Average lifetime\n",
    "- Number of relevant holes\n",
    "- Amplitude\n",
    "- Mean support feature and argmax feature of the Betti curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_lifetime(persistence_diagrams, h_dim):\n",
    "    \"\"\"From the persistence diagrams detect the average lifetime for a given homology dimension. \n",
    "       Then, assign a value to each initial data points.\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       persistence_diagrams : np.array, required\n",
    "            The persistence diagrams on which to compute the feature_extraction.\n",
    "    \n",
    "       h_dim : int, required\n",
    "           The dimension of the homology to consider for the feature creation.\n",
    "\n",
    "       Returns\n",
    "       -------\n",
    "       avg_lifetime : np.array\n",
    "           The average lifetime feature values.\n",
    "\n",
    "    \"\"\"\n",
    "    avg_lifetime = []\n",
    "\n",
    "    for i in range(persistence_diagrams.shape[0]):\n",
    "        persistence_table = pd.DataFrame(\n",
    "            persistence_diagrams[i], columns=[\"birth\", \"death\", \"homology\"]\n",
    "        )\n",
    "        persistence_table[\"lifetime\"] = (\n",
    "            persistence_table[\"death\"] - persistence_table[\"birth\"]\n",
    "        )\n",
    "        avg_lifetime.append(\n",
    "            persistence_table[persistence_table[\"homology\"] == h_dim][\n",
    "                \"lifetime\"\n",
    "            ].mean()\n",
    "        )\n",
    "\n",
    "    return avg_lifetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_num_relevant_holes(persistence_diagrams, h_dim, theta):\n",
    "    \"\"\"From the persistence diagrams detect the average lifetime for a given homology dimension. \n",
    "       Then, assign a value to each initial data points.\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       persistence_diagrams : np.array, required\n",
    "            The persistence diagrams on which to compute the feature_extraction.\n",
    "    \n",
    "       h_dim : int, required\n",
    "           The dimension of the homology to consider for the feature creation.\n",
    "    \n",
    "       theta : float, required\n",
    "           The threshold ratio. Value between 0 and 1.\n",
    "\n",
    "       Returns\n",
    "       -------\n",
    "       n_rel_holes : np.array\n",
    "           The 'number of relevant holes' feature values.\n",
    "           \n",
    "    \"\"\"\n",
    "    n_rel_holes = []\n",
    "    for i in range(persistence_diagrams.shape[0]):\n",
    "        pers_table = pd.DataFrame(\n",
    "            persistence_diagrams[i], columns=[\"birth\", \"death\", \"homology\"]\n",
    "        )\n",
    "\n",
    "        pers_table[\"lifetime\"] = pers_table[\"death\"] - pers_table[\"birth\"]\n",
    "        threshold = (\n",
    "            pers_table[pers_table[\"homology\"] == h_dim][\"lifetime\"].max()\n",
    "            * theta\n",
    "        )\n",
    "        n_rel_holes.append(\n",
    "            pers_table[\n",
    "                (pers_table[\"lifetime\"] > threshold)\n",
    "                & (pers_table[\"homology\"] == h_dim)\n",
    "            ].shape[0]\n",
    "        )\n",
    "    return n_rel_holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean_nonzero(g):\n",
    "    \"\"\" Helper function for Betti features.\n",
    "    \"\"\"\n",
    "    if g.to_numpy().nonzero()[1].any():\n",
    "        return g.to_numpy().nonzero()[1].mean()\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def compute_betti_features(X_betti_curves, betti_mode, betti_homology_dimension=0, betti_rolling=3):\n",
    "    \"\"\" Calculate the feature from the Betti curves.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        X_betti_curves : np.array, required\n",
    "            The Betti curve to create the feature from.\n",
    "\n",
    "        betti_mode : string, required\n",
    "            Choose the type of feature: Either 'mean' or 'arg_max'. \n",
    "\n",
    "        betti_homology_dimension : int, default=0\n",
    "            Dimension of the homology to use.\n",
    "\n",
    "        betti_rolling : int, default=3\n",
    "            The rolling window size for the feature creation.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        betti_features : np.array\n",
    "            The 'Betti curves' feature values.\n",
    "\n",
    "    \"\"\"\n",
    "    betti_curves = pd.DataFrame(X_betti_curves[:, betti_homology_dimension, :])\n",
    "\n",
    "    if betti_mode == \"mean\":\n",
    "        betti_features = compute_betti_mean(betti_curves, betti_rolling)\n",
    "\n",
    "    elif betti_mode == \"arg_max\":\n",
    "        betti_features = compute_arg_max_by_time(betti_curves)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"The valid values for 'betti_mode' are 'mean' \"\n",
    "            f\"or 'arg_max', instead has value \"\n",
    "            f\"{betti_mode}.\"\n",
    "        )\n",
    "\n",
    "    return betti_features\n",
    "\n",
    "def compute_betti_mean(betti_surface, betti_rolling):\n",
    "    \"\"\"Helper function for Betti features.\n",
    "    \"\"\"\n",
    "    betti_means = (betti_surface.groupby(betti_surface.index)\n",
    "                   .apply(lambda g: find_mean_nonzero(g))\n",
    "                   .rolling(betti_rolling)\n",
    "                   .mean()\n",
    "                   .values)\n",
    "    return betti_means\n",
    "\n",
    "def compute_arg_max_by_time(betti_surfaces):\n",
    "    \"\"\"Helper function for Betti features.\n",
    "    \"\"\"\n",
    "    betti_arg_maxes = []\n",
    "    for betti_surface in betti_surfaces:\n",
    "        arg_max = np.argmax(np.array(betti_surface), axis=1)\n",
    "        betti_arg_maxes.append(arg_max)\n",
    "\n",
    "    return betti_arg_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = lambda d: compute_average_lifetime(d, 0)\n",
    "avg_liftime_ft = FunctionTransformer(func)\n",
    "\n",
    "func = lambda d: compute_num_relevant_holes(d, 0, 0.7)\n",
    "num_rel_holes_ft = FunctionTransformer(func)\n",
    "\n",
    "func = lambda bs: compute_betti_features(bs, betti_mode='mean')\n",
    "betti_features_ft = FunctionTransformer(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the TDA pipelines\n",
    "We can define pipelines that take the TDA methods defined above. Then, the output can be reshaped into a pandas dataframe with the appropriate size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_lifetime_feature(df):\n",
    "    tda_pipeline_avg_lifetime = Pipeline(steps=[ \n",
    "                                                 ('takens', takens_embedding),\n",
    "                                                 ('sliding_window', sliding_window),\n",
    "                                                 ('vietoris_rips', vietoris_rips_persistence),\n",
    "                                                 ('scaler', diagram_scaler),\n",
    "                                                 ('avg_lifetime', avg_liftime_ft)\n",
    "                                               ])\n",
    "\n",
    "    lifetime_feature = tda_pipeline_avg_lifetime.fit_transform(df)\n",
    "    n_points = compute_n_points(len(lifetime_feature), \n",
    "                                sliding_stride, \n",
    "                                sliding_window_width, \n",
    "                                takens_stride, \n",
    "                                takens_dimension, \n",
    "                                embedding_time_delay)\n",
    "\n",
    "    res = align_indices(df, n_points, lifetime_feature)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_rel_holes_feature(df):\n",
    "    tda_pipeline_num_rel_holes = Pipeline(steps=[ \n",
    "                                                  ('takens', takens_embedding),\n",
    "                                                  ('sliding_window', sliding_window),\n",
    "                                                  ('vietoris_rips', vietoris_rips_persistence),\n",
    "                                                  ('scaler', diagram_scaler),\n",
    "                                                  ('num_rel_holes', num_rel_holes_ft)\n",
    "                                                ])\n",
    "\n",
    "    holes_feature = tda_pipeline_num_rel_holes.fit_transform(df)\n",
    "    n_points = compute_n_points(len(holes_feature), \n",
    "                                sliding_stride, \n",
    "                                sliding_window_width, \n",
    "                                takens_stride, \n",
    "                                takens_dimension, \n",
    "                                embedding_time_delay)\n",
    "\n",
    "    res = align_indices(df, n_points, holes_feature)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_betti_feature(df):\n",
    "    tda_pipeline_betti_feature = Pipeline(steps=[ \n",
    "                                                  ('takens', takens_embedding),\n",
    "                                                  ('sliding_window', sliding_window),\n",
    "                                                  ('vietoris_rips', vietoris_rips_persistence),\n",
    "                                                  ('scaler', diagram_scaler),\n",
    "                                                  ('betti_feature', betti_features_ft)\n",
    "                                                ])\n",
    "\n",
    "    betti_feature = tda_pipeline_betti_feature.fit_transform(df)\n",
    "    n_points = compute_n_points(len(betti_feature), \n",
    "                                sliding_stride, \n",
    "                                sliding_window_width, \n",
    "                                takens_stride, \n",
    "                                takens_dimension, \n",
    "                                embedding_time_delay)\n",
    "\n",
    "    res = align_indices(df, n_points, betti_feature)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_amplitude(df):\n",
    "    tda_pipeline_amplitude_feature = Pipeline(steps=[ \n",
    "                                                      ('takens', takens_embedding),\n",
    "                                                      ('sliding_window', sliding_window),\n",
    "                                                      ('vietoris_rips', vietoris_rips_persistence),\n",
    "                                                      ('scaler', diagram_scaler),\n",
    "                                                      ('amplitude', amplitude)\n",
    "                                                    ])\n",
    "\n",
    "    amplitude_feature = tda_pipeline_amplitude_feature.fit_transform(df)\n",
    "    n_points = compute_n_points(len(amplitude_feature), \n",
    "                                sliding_stride, \n",
    "                                sliding_window_width, \n",
    "                                takens_stride, \n",
    "                                takens_dimension, \n",
    "                                embedding_time_delay)\n",
    "\n",
    "    res = align_indices(df, n_points, amplitude_feature)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the time series feature creation pipeline\n",
    "Now we can use the transformers defined above in the feature creation methods of giotto-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_creation = FeatureCreation([\n",
    "                                    ('average_lifetime', CustomFeature(get_avg_lifetime_feature), ['value']),\n",
    "                                    ('num_holes', CustomFeature(get_num_rel_holes_feature), ['value']),\n",
    "                                    ('betti_feature', CustomFeature(get_betti_feature), ['value']),\n",
    "                                    ('amplitude', CustomFeature(get_amplitude), ['value'])\n",
    "                                   ])\n",
    "\n",
    "res = feature_creation.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
